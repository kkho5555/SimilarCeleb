{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 491 images belonging to 20 classes.\nFound 226 images belonging to 20 classes.\nFound 226 images belonging to 20 classes.\nEpoch 1/50\n125/125 [==============================] - 46s 365ms/step - loss: 3.0594 - accuracy: 0.0596 - val_loss: 2.9955 - val_accuracy: 0.0778\nEpoch 2/50\n125/125 [==============================] - 45s 358ms/step - loss: 2.8287 - accuracy: 0.1338 - val_loss: 2.8004 - val_accuracy: 0.2665\nEpoch 3/50\n125/125 [==============================] - 45s 359ms/step - loss: 2.4990 - accuracy: 0.2399 - val_loss: 1.1944 - val_accuracy: 0.3925\nEpoch 4/50\n125/125 [==============================] - 45s 359ms/step - loss: 2.2292 - accuracy: 0.3237 - val_loss: 2.2450 - val_accuracy: 0.3984\nEpoch 5/50\n125/125 [==============================] - 45s 362ms/step - loss: 1.9663 - accuracy: 0.3949 - val_loss: 2.2661 - val_accuracy: 0.4485\nEpoch 6/50\n125/125 [==============================] - 45s 359ms/step - loss: 1.8168 - accuracy: 0.4317 - val_loss: 1.3065 - val_accuracy: 0.4785\nEpoch 7/50\n125/125 [==============================] - 45s 356ms/step - loss: 1.6186 - accuracy: 0.4904 - val_loss: 1.6440 - val_accuracy: 0.5264\nEpoch 8/50\n125/125 [==============================] - 44s 355ms/step - loss: 1.5221 - accuracy: 0.5167 - val_loss: 1.7997 - val_accuracy: 0.5198\nEpoch 9/50\n125/125 [==============================] - 45s 357ms/step - loss: 1.3909 - accuracy: 0.5500 - val_loss: 3.2390 - val_accuracy: 0.4543\nEpoch 10/50\n125/125 [==============================] - 45s 357ms/step - loss: 1.2964 - accuracy: 0.5782 - val_loss: 1.7538 - val_accuracy: 0.5475\nEpoch 11/50\n125/125 [==============================] - 45s 360ms/step - loss: 1.1782 - accuracy: 0.6157 - val_loss: 2.0525 - val_accuracy: 0.6148\nEpoch 12/50\n125/125 [==============================] - 45s 358ms/step - loss: 1.1352 - accuracy: 0.6242 - val_loss: 0.6809 - val_accuracy: 0.5914\nEpoch 13/50\n125/125 [==============================] - 46s 365ms/step - loss: 1.0761 - accuracy: 0.6687 - val_loss: 2.3056 - val_accuracy: 0.5989\nEpoch 14/50\n125/125 [==============================] - 45s 359ms/step - loss: 1.0545 - accuracy: 0.6475 - val_loss: 1.4266 - val_accuracy: 0.5989\nEpoch 15/50\n125/125 [==============================] - 45s 360ms/step - loss: 0.8981 - accuracy: 0.7068 - val_loss: 2.6316 - val_accuracy: 0.5793\nEpoch 16/50\n125/125 [==============================] - 45s 361ms/step - loss: 0.9377 - accuracy: 0.7018 - val_loss: 1.6088 - val_accuracy: 0.6319\nEpoch 17/50\n125/125 [==============================] - 45s 360ms/step - loss: 0.8955 - accuracy: 0.7187 - val_loss: 1.1925 - val_accuracy: 0.6003\nEpoch 18/50\n125/125 [==============================] - 45s 360ms/step - loss: 0.8443 - accuracy: 0.7271 - val_loss: 0.3853 - val_accuracy: 0.6237\nEpoch 19/50\n125/125 [==============================] - 45s 363ms/step - loss: 0.8239 - accuracy: 0.7384 - val_loss: 2.6532 - val_accuracy: 0.5871\nEpoch 20/50\n125/125 [==============================] - 45s 362ms/step - loss: 0.7684 - accuracy: 0.7380 - val_loss: 0.7881 - val_accuracy: 0.5778\nEpoch 21/50\n125/125 [==============================] - 45s 362ms/step - loss: 0.7763 - accuracy: 0.7485 - val_loss: 3.2059 - val_accuracy: 0.5551\nEpoch 22/50\n125/125 [==============================] - 45s 361ms/step - loss: 0.7063 - accuracy: 0.7626 - val_loss: 2.2714 - val_accuracy: 0.6385\nEpoch 23/50\n125/125 [==============================] - 46s 369ms/step - loss: 0.7129 - accuracy: 0.7677 - val_loss: 1.4685 - val_accuracy: 0.6201\nEpoch 24/50\n125/125 [==============================] - 45s 363ms/step - loss: 0.7475 - accuracy: 0.7565 - val_loss: 2.5408 - val_accuracy: 0.6075\nEpoch 25/50\n125/125 [==============================] - 47s 372ms/step - loss: 0.7227 - accuracy: 0.7576 - val_loss: 2.4298 - val_accuracy: 0.6438\nEpoch 26/50\n125/125 [==============================] - 46s 365ms/step - loss: 0.6618 - accuracy: 0.7783 - val_loss: 0.3876 - val_accuracy: 0.6557\nEpoch 27/50\n125/125 [==============================] - 46s 371ms/step - loss: 0.7012 - accuracy: 0.7803 - val_loss: 0.6257 - val_accuracy: 0.6505\nEpoch 28/50\n125/125 [==============================] - 46s 366ms/step - loss: 0.6468 - accuracy: 0.8000 - val_loss: 1.1018 - val_accuracy: 0.5989\nEpoch 29/50\n125/125 [==============================] - 45s 363ms/step - loss: 0.6616 - accuracy: 0.7879 - val_loss: 2.3343 - val_accuracy: 0.6029\nEpoch 30/50\n125/125 [==============================] - 45s 362ms/step - loss: 0.6149 - accuracy: 0.8035 - val_loss: 1.0982 - val_accuracy: 0.5806\nEpoch 31/50\n125/125 [==============================] - 46s 367ms/step - loss: 0.6578 - accuracy: 0.7909 - val_loss: 3.2613 - val_accuracy: 0.6135\nEpoch 32/50\n125/125 [==============================] - 45s 360ms/step - loss: 0.6213 - accuracy: 0.7985 - val_loss: 2.0684 - val_accuracy: 0.6174\nEpoch 33/50\n125/125 [==============================] - 45s 359ms/step - loss: 0.6109 - accuracy: 0.8157 - val_loss: 0.9016 - val_accuracy: 0.6344\nEpoch 34/50\n125/125 [==============================] - 45s 360ms/step - loss: 0.5975 - accuracy: 0.8187 - val_loss: 0.9922 - val_accuracy: 0.6491\nEpoch 35/50\n125/125 [==============================] - 45s 360ms/step - loss: 0.5731 - accuracy: 0.8146 - val_loss: 4.6548 - val_accuracy: 0.6412\nEpoch 36/50\n125/125 [==============================] - 45s 361ms/step - loss: 0.5942 - accuracy: 0.8258 - val_loss: 2.9793 - val_accuracy: 0.6008\nEpoch 37/50\n125/125 [==============================] - 46s 365ms/step - loss: 0.5898 - accuracy: 0.8106 - val_loss: 0.9025 - val_accuracy: 0.6596\nEpoch 38/50\n125/125 [==============================] - 45s 359ms/step - loss: 0.5750 - accuracy: 0.8167 - val_loss: 1.7721 - val_accuracy: 0.5923\nEpoch 39/50\n125/125 [==============================] - 45s 362ms/step - loss: 0.5952 - accuracy: 0.8171 - val_loss: 0.1969 - val_accuracy: 0.6344\nEpoch 40/50\n125/125 [==============================] - 45s 362ms/step - loss: 0.4873 - accuracy: 0.8385 - val_loss: 0.5676 - val_accuracy: 0.6359\nEpoch 41/50\n125/125 [==============================] - 45s 361ms/step - loss: 0.5249 - accuracy: 0.8354 - val_loss: 1.6577 - val_accuracy: 0.6438\nEpoch 42/50\n125/125 [==============================] - 45s 361ms/step - loss: 0.6089 - accuracy: 0.8106 - val_loss: 0.0168 - val_accuracy: 0.6210\nEpoch 43/50\n125/125 [==============================] - 46s 364ms/step - loss: 0.5432 - accuracy: 0.8317 - val_loss: 3.3448 - val_accuracy: 0.5818\nEpoch 44/50\n125/125 [==============================] - 46s 364ms/step - loss: 0.5499 - accuracy: 0.8333 - val_loss: 1.3921 - val_accuracy: 0.6385\nEpoch 45/50\n125/125 [==============================] - 45s 364ms/step - loss: 0.5018 - accuracy: 0.8404 - val_loss: 5.8232 - val_accuracy: 0.6102\nEpoch 46/50\n125/125 [==============================] - 45s 361ms/step - loss: 0.5461 - accuracy: 0.8344 - val_loss: 0.8997 - val_accuracy: 0.5910\nEpoch 47/50\n125/125 [==============================] - 45s 360ms/step - loss: 0.5620 - accuracy: 0.8242 - val_loss: 1.7326 - val_accuracy: 0.6148\nEpoch 48/50\n125/125 [==============================] - 45s 363ms/step - loss: 0.5177 - accuracy: 0.8268 - val_loss: 3.5422 - val_accuracy: 0.5712\nEpoch 49/50\n125/125 [==============================] - 45s 363ms/step - loss: 0.5186 - accuracy: 0.8384 - val_loss: 1.9698 - val_accuracy: 0.6227\nEpoch 50/50\n125/125 [==============================] - 46s 364ms/step - loss: 0.5719 - accuracy: 0.8202 - val_loss: 1.6524 - val_accuracy: 0.6332\n"
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "'''\n",
    "#### File Tree ####\n",
    "다음과 같이 구성하고 실행하세요\n",
    "\n",
    "- source\n",
    "    - test.ipynb\n",
    "- train\n",
    "  - 1\n",
    "    - 1_01.jpg\n",
    "    - ...\n",
    "  - 2\n",
    "    - 2_02.jpg\n",
    "    - ...\n",
    "- validation\n",
    "  - 1\n",
    "    - 1_01.jpg\n",
    "    - ...\n",
    "  - 2\n",
    "    - 2_02.jpg\n",
    "    - ...\n",
    "\n",
    "'''\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = '../train'\n",
    "validation_data_dir = '../validation'\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "epochs = 50 ## 임의의 훈련 진행횟수\n",
    "batch_size = 16\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "#### 순차적인(일렬) 모델 생성\n",
    "## 히든레이어 1\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "## 히든레이어 2 \n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "## 히든레이어 3\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "## Drop 레이어\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(20))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "## 모델 컴파일\n",
    "## 2개 (ex:개 or 고양이 분류)) 일땐 binary 를 사용하며 그이상일 경우 categorical 사용\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "## ImageDataGenerator 는 임의의 이미지를 생성하는 함수이며\n",
    "## 여기선 훈련용 데이터가 부족하기 때문에 원본 사진에서 스케일링, 사진회전, 좌우반전등을 통해 훈련용 이미지를 증가시킨다\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "## 훈련용 이미지를 지외하고 검증용, 테스트용은 원본사진으로 하기위해 리스케일만 진행한다.\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "## flow_from_directory 는 앞서 생성한 임의의 이미지를 불러오는 함수\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "## 모델 훈련\n",
    "## Tensor flow GPU 모드를 사용하면 약 90% 빨라진다.\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "## 모델 학습이 오래걸리기 때문에 저장하여 나중에 다양하게 활용한다.\n",
    "## ex) 보강학습, 모델검증 등등\n",
    "model.save_weights('first_try.h5')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}